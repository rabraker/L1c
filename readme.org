#+TITLE: l1C: Compressed Sensing in c
#+SETUPFILE: ~/.emacs.d/org-templates/level-0.org
#+PROPERTY: TEMPLATE page_math
#+PROPERTY: URL projects/l1c.html 
#+PROPERTY: SAVE_AS projects/l1c.html
#+OPTIONS: tex:t
#+STARTUP: latexpreview
#+TODO: TODO(t) WAITING(w@/!) | DONE(d@/!) CANCELED(c@/!) STARTED(s@/!) DEFERRED(ef@/!)
#+SEQ_TODO: TODO STARTED WAITING DELEGATED APPT | DONE DEFERRED CANCELLED



* Introduction
The goal of this project is to provide a c library that is useful to compressed sensing.  To date, lots of research has been produced that develops methods to efficiently solve solve various formulations of the compressed sensing problem. To their great credit, many of those reasearchers have released code along with their publications. See, for example, [[https://statweb.stanford.edu/~candes/l1magic/][l1-magic]], [[http://statweb.stanford.edu/~candes/nesta/][NESTA]], [[https://sparselab.stanford.edu/][SparseLab]], and [[https://www.ece.rice.edu/~tag7/Tom_Goldstein/Split_Bregman.html][Split Bregman]]. So, a good question is, why re-do it in c?

- Much of the published code is written in Matlab. This means if you want to use the code in a Python or R or Julia or a c/c++ project, you must translate the Matlab code to your language. By contrast, c is something like the langua franca of computing. It is relatively straigtforward to interface c code with most languages, including Matlab.

- CS optimizations are computationally intensive. Thus, it seems beneficial to write optimized implementations of those optimizations and c fits that requirement (Fortran might be better, but I have forgotten it).

- c is fun (probably the main reason)

 
Presently, the only capability this library provides is to solve the problem

\begin{aligned}
\min_{x} ||x||_{1}  \quad \text{s.t.} \quad ||Ax -b||_{2} < \epsilon,
\end{aligned}

which, is mostly a port of ~l1qc_log_barrier.m~ from the ~l1-magic~ code, with a few modifications. Currently, the code *only* operates in large-scale mode, which means that the transformation $Ax$ (and the adjoint, $A^Ty$) are performed by user supplied functions, rather than an explicit matrix-vector multiplication. This also means that solving for the descent direction is always done via conjugate gradients.

* Performance
So far, using ~l1C~ gives me a speed increase of between 2 and 5 times faster compared to the original matlab code, depending on which computer I run it on.

If you compile with FFTW+OpenBlas, it is important that both libraries are compiled with openmp. I dont quite understand what happens, but if this is not the case, performance can suffer dramatically. In addition, if you have a CPU with hyperthreading, it is important to export the environmental variable

>> export OMP_NUM_THREADS=N

where N is the number of physical cores (essentially, if you have HT, this is half the the number of processors you see in a resource monitor). The code currently can not detect this (only the number of logical cores) and for number crunching applications like this one, HT is detrimental.

* Building
Typing ~make~ in the root directoy will print a summary of availible targets and options. To summarize, the availible targets are:
- ~make test~, will build the unit tests and output a file in the ~lqc~ root directoy called ~test_l1qc~.
- ~make test_data~, will launch matlab as a terminal application and build the test data, which is derived from the original ~l1-magic~ Matlab implementation.
- ~make mex~, will build a mex style interface for Matlab. Note that, due to the requirement of supplying user-defined functions which evaluate $Ax$ and $A^{T}y$, this target is best thought of as an example. You will want to modify the mex file for your particular application. 
  - Currently, I do not link into shared libraries when building the mex file, but rather link the archive (which fortunately both OpenBlas, FFTW and MKL supply) so that the mex function is completely self contained. This eliminates all the problems with Matlab not respecting your ~LD_LIBRARY_PATH~. If you know how to make that work consistently, let me know!
  - The makefile assumes your Matlab is installed at /usr/local/MATLAB/R2018b. If this is not the case, modify the makefile variable ~MATLAB_ROOT~.
- ~make lib~, which will build a shared .so style library. This is probably only useful if we want to use ~l1c~ with other, non-matlab code. See above.
- ~make ar~, will build an archive file (.a). 
- Options. Currently, you can supply two different options.
  - ~USE_MKL=[1|0]~. If 1, the library will be build using MKL. Otherwise, it will be built with OpenBlas and FFTW. Default is 0. If ~USE_MKL=1~, the makefile will assume that your MKL is installed in 
    ~/opt/intel/compilers_and_libraries/linux/mkl~. If this is not the case, you can either comment out the ~MKLROOT~ variable in the makefile and export the proper location before running make or modify the variable in the makefile.
  - ~DEBUG=[1|0]~. If 1, build with debugging symbols and turn optimizations off. Default is 0. To debug with optimizations on, please edit the makefile, (e.g., add ~-g~ to ~CFLAGS~).
** Dependencies
*** Core Code
The core code with examples requires a linear algebra library and an FFT library capable of performing a DCT. The best performance I have seen is by compiling with Intel's [[https://software.intel.com/en-us/mkl][Math Kernel Library (MKL)]]. I believe most of the increased performance is due to their faster DCT routines. 

This is, however, unecessary and ~l1C~ can be built with [[https://github.com/xianyi/OpenBLAS][OpenBlas]] and FFTW could be used, as in ~interfaces/l1qc_fftw.c~.

Note that in general, the only use of the DCT is for the (user defined) $A*x$ and $A^{T}*y$ transformations. If your use case uses a different sort of transformation, then an FFT library is unecessary. If this is the case, then you can simply adapt the mex interface file to your needs. Running the tests would require you to modify them and supply a different transformation, and to eliminate the tests for dct.c and dct_mkl.c.

*** Unit Tests
The unit tests depend on two additional libraries. Data for the unit tests is generated in Matlab for the more complicated functions. Data for simple routines is embedded within the test function itself (see, e.g., ~TEST_vcl.c~ and ~test_logsum()~ in ~TEST_l1qc_newton.c~).
1. [[https://github.com/libcheck/check][libcheck]] is the unit testing framework. The makefile assumes the headers for check are located in 
 ~/usr/local/include~ and that libcheck.so is located in ~/usr/local/lib~.
2. To load data generated by matlab, we use [[https://github.com/DaveGamble/cJSON][cJSON]].
3. Saving data in Matlab/octave is accomplished with [[https://github.com/fangq/jsonlab][jsonlab]].

It is highly recommended to install these dependencies and run the tests.
** Building the test data

1. ~build_log_barrier_test_data.m~: this scripts builds data to test the outer log-barrier iterations. JSON files are saved into test_data with the name ~sprintf('lb_test_data_iter_%d.json', lb_iter)~.
2. ~~build_newton_init_data.m~ Builds a small set of data to check that we compute the number of log-barrier iterations and tau parameter properly. Used in ~test_newton_init()~.
* Usage
As a user, the primary function you need to worry about is
#+BEGIN_SRC c 

/*l1qc_newton.h */
LBResult l1qc_newton(int N, double *x, double *u, int M, double *b, 
                     NewtParams params, AxFuns Ax_funs;
#+END_SRC

- ~int N~. The length of ~x~ and ~u~.
- ~double *x~. On entry, this should be an array of doubles length N, allocated on a 64-byte boundary (see below). On exit, x contains the result of the optimization.
- ~double *u~ On entry, this should contain an array with length N. On exit, it will contain the auxilary u (See above about the conversion from an l1 optimization to a linear program).
- ~int M~. The length b.
- ~double *b~. On entry, contains the 'measured data' (see above). In general, we expect M <N.
- ~NewtParams params~ is a struct containing parameters (e.g., tolerances and iteration number bounds). Will be described fully below.
- ~AxFuns Ax_funs~ is a struct containing pointers to the functions which perform the transformations.


*Important*: The array inputs of doubles (*x, *u, *b) to ~l1qc_newton~ must be aligned on a 64-byte boundary, otherwise segfaults may occur. To faciliate this, you may use the functions. 

#+BEGIN_SRC c 
/*l1c_common.h */
void* malloc_double(N);
void* free_double(N);
#+END_SRC
The function ~malloc_double(N)~ will allocate memory for ~N~ doubles, aligned on a 64-byte boundary and ~free_double~ will free it.


The data structures are defined as
#+BEGIN_SRC c
//l1qc_newton.h
typedef struct LBResult{
  double l1;                // Final value of functional, ||x||_1
  int    total_newton_iter; // Total number of newton iterations.
  int    status;            // 0 if completed with no errors, 1 otherwise

}LBResult;

typedef struct NewtParams{
  double epsilon;
  double tau;
  double mu;
  double newton_tol;
  int newton_max_iter;
  int lbiter;
  double lbtol;
  int verbose;
  CgParams cg_params;

}NewtParams;

typedef struct AxFuns {
  void(*Ax)(double *x, double *y);
  void(*Aty)(double *y, double *x);
  void(*AtAx)(double *x, double *z);
}AxFuns;
#+END_SRC

The struct ~AxFuns~ contains pointers to your user-defined functions which compute $Ax$ and $A^{T}y$. For an example, see the mex-interface file ~l1qc_mex.c~ (in ~interfaces/~) and either ~dct.c~ or ~dct_mkl.c~. Note that although the mex interface looks long and complicated, almost all of this is boiler-plate parsing of Matlab's input to the function. The amount of code to modify for a different set of transform functions is only a few lines.

* Modifications from the ~l1-magic~ algorithm
I have made a few changes (improvements?) to the original ~~l1-magic~ algorithm, both pertaining to the line search. I believe these changes add issues with numerical, rather than mathematical, problems. As the ~l1-magic~ authors note, in the later stages of the optimziation, numerical difficulties arise and the line search can fail. These modifications help to push that point into the future, enabling more iterations.

1. In the original code, I noticed that at some point, the data become complex when it should have been purely real. One of the places where this occures is in the code which computes the maximum step-size which still satisfies the constraints (i.e., lines XX in the original code). In particular, the code which computes the largest number $s$ such such that, for $x_{k+1}= x_{k} + sd_{x_k}$, $||Ax_{k+1}-b||<\epsilon$ still holds. To do this, we expand into a scalar equation quadratic in $s$
   \begin{align}
   ||A(x+sd_{x})-b||^{2} - \epsilon^{2} &=0 \\
   s^{2}(d_x^{T}A^{T}Ad_x) + 2r^{T}Ad_x + r^{T}r - \epsilon^{2} &= 0\\
   \end{align}

   where $r = Ax - b$. Although the roots should always be real, due to either computing $d_{x}$ with insufficient accuracy (which accomplished via conjugate gradient) or otherwise, the roots become complex in the later stages. In matlab, the promation to a complex type happens silently and we start optimizing complex data, which is undersirable. In c, the ~sqrt~ operation simply returns NaN, which is also undersirable. When this happens, the modification is to set $s=1$ and let the line search deal with. This will work fine in c because taking the log of a negative number results in NaN. In Matlab, we need something like ~log(max(0, a))~.

2. The goal of the line-search is to find (approximitaly) the largest step-size $s$ such that
   \begin{equation}
   f(z + sd_{z}) < f(z) + \alpha s \nabla f\cdot d_{z}
   \end{equation}
   In the original code, the functional $f(z)$ is only evaluated explicitly at the start of each log-barrier iteration and the value of $f(z_{i})$ is updated from derived values, e.g., $r_{k+1}= r_{k} + sAd_{x}$. Mathematically, this is fine. Numerically, it is problematic because after enough iterations the explicit value of $f(z_{k})$ becomes infinite (due to the barrier functions) even though the putative value is finite. Thus, although it is less efficient, this code evaluates the functional explicitly at each iteration of the line-search and this value is then passed to the next Newton iteration.

** To-Dos
1. Make ~MATLAB_ROOT~ and ~MKLROOT~ set-able from the commandline, or figure out a way to detect them.

2. Need an aligned memory allocator for when we don't have MKL.

3. Figure out the license. This may mean re-working all the test code because ~l1-magic~ doesn't come with an explicit license.
4. Make it build on windows, at least using cygwin or mingw.
5. Other optimization routines. On the list are
   - The TV-denoising problem using Bregman iteration. This seems like a really nice way to reduce much of the noise CS reconstructions.
   - [[https://web.stanford.edu/~boyd/l1_ls/][l1-ls]] from Stephen Boyd's research group.
   - NESTA, which from my cursory inspection, seems to depend on l1-ls.

6. Generalize the backtracking line search. There is really no reason that it needs to be specific to the l1qc algorithm. All it needs is a way to evaluate the functional and gradient at different step sizes.

7. With a bit of work, it should be possible to generalize the entire set of log-barrier and newton iterations, so that it is not specific the quadratically constrained l1 problem. Basically, all that is required is
   - A function to evaluate the functional
   - A function to compute the descent direction
   - A function to compute the linear approximation for the linesearch
   - A function to compute the max-step size. This seems like the main difference to a standard Newton descent algorithm and this one with barrier functions.
   - A function to compute the stopping criteria.

